Lecture: http://techtv.mit.edu/collections/bcs/videos/30698-what-s-wrong-with-convolutional-nets

[2:00] Slide này nêu 2 nhược điểm của CNN:

Nhược điểm 1: "Too few level of structure" -> cái này thì rõ ràng rồi, mạng neuron của con người có hàng tỷ neurons và vô cùng phức tạp 
đến nỗi không ai hiểu được, mạng CNN phổ biến thì chỉ có vài mống layer. Mạnh nhất là mạng DenseNet có hơn 1k layers nhưng 
1k là quá khiêm tốn so với não người.
    
Nhược điểm 2: "need to group the neurons in each layer into capsules that do a lot of internal computation and then output a compact result."
Cái này thì mình không hiểu lắm là bác ấy định nói gì. Slide sau [2:50] bác ấy nói rằng một capsule thể hiện một 
"multi-dimensional entity of the type that the capsule detects", và "a capsule detects two things:"
-1. The probability that an object of that type is present.
-2. The generalized pose of the object which includes position, orientation, scale, deformation, velocity, color, etc...

Thật sự là đến đây mới chỉ nghe có 3 phút nhưng mình đã lại nhớ cái hồi học khóa NN của bác này trên Coursera: cảm giác rất nản vì không biết
bác ấy định nói gì. Kiểu cứ một mình bác chơi một kiểu từ vựng. Filter thì gọi quách là filter, feature map thì gọi quách là feature map.
Sao phải gọi là "capsule"? Mà "group the neurons into capsules that do a lot of internal computation" thì liên quan gì tới nhược điểm?
Với lại capsule tại sao lại vừa thể hiện một số (probability), vừa thể hiện một vector toán học (multi-dimensional entity), lại vừa thể hiện
features 2D (position, orientation, velocity), rồi lại đại lượng số học (scale, color)? Nói chung là khó chịu. Sau 2 năm học đủ các thứ
trên đời thì bài giảng của bác Hinton này là khó nuốt nhất.

[8:28] On pooling layer: "The fact that it works so well is extremely unfortunate because that makes it harder to get rid of" :)) 
đúng là ngữ khí của bậc đại cao thủ, sẵn sàng phê phán tới cùng một kiến trúc thần thánh đã làm điên đảo thế giới. Những nghiên cứu gần đây
về Fully Convolutional Nets (FCN hoặc FCNN) đã chứng minh là nhận định của bác Hinton là hoàn toàn có cơ sở, khi mà pooling layer
thật ra là không cần thiết và có thể mô phỏng pooling bằng non-overlapping conv layer. Cách bác Hinton đặt vấn đề và diễn giải cho thấy
một nội công Cửu Dương thần công tinh thuần bá đạo của 1 người đã làm neural net từ những năm 87s.

[9:04] On activation: "The activations in the last hidden layer of a deep convnet are a percept", có thể dịch là "activations của 
lớp hidden layer cuối cùng của một mạng CNN là một sự nhận thức". Trong câu này có rất nhiều điểm đáng chú ý: lớp hidden cuối cùng là 
lớp nào? Là lớp convolution cuối cùng hay là lớp fully connected cuối cùng? Đặc biệt hơn cả là khái niệm "percept". Activations của
cái lớp cuối cùng này không chỉ là một đống số thực vô tri vô giác mà là một "nhận thức". 

[13:51] "So I'm gonna give you an example that illustrates the power of coordinate frame" => epic example, reminds me TBBT every time :))
On a serious note, the example does have a very good point: each half of the tetrahedron can be seen as primitive features, and if it's
so hard for us to combine these two features together in a good way (e.g. come up with good coordinate frames)
, how could we expect coordinate-lacking ANN (especially CNN) to do that? At this point I start feel like CNN and RNN are our heros who have different
super powers, just like the Flash and Superman, yet they are not gods and have weeknesses.

[23:48] Tổng kết Conclusion của argument 1: đến đây ta thấy rõ hơn là tại sao cái "nhận thức" lại liên kết tới ví dụ ở trên. Vì 
activations của neurons trong não người thể hiện một nhận thức, mà nhận thức ấy thay đổi cực nhiều theo hệ quy chiếu (frame) được nhúng
trong các vật thể xung quanh ta ("frames embedded in objects"), nên đây rõ ràng là điểm yếu của CNN khi một mạng CNN chỉ có thể phản 
ánh cái frame của người chụp ảnh tạo ra dataset cho nó mà thôi. Đây sẽ là một luận điểm quan trọng khi làm object segmentation trong occluded
environment, khi mà khung cảnh bị ảnh hưởng nặng nề bởi các vật thể khác. Hệ quả thú vị hơn là có thể trong tương lai nếu ANN có cơ chế
tốt hơn não người thì con người sẽ không thể verify hoặc analyze các thuật toán AI bằng manual error analysis được nữa, vì những gì AI
nhìn thấy sẽ khác con người nhìn thấy.

